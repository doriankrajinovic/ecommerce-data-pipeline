# ğŸ“š Parquet - Columnar Storage Format

## Gdje smo u projektu?

```
[1. Pydantic] â†’ [2. Faker] â†’ [3. PARQUET] â†’ [4. BigQuery] â†’ [5. dbt] â†’ [6. Airflow]
     âœ…            âœ…           ğŸ‘ˆ TU SMO
```

## ZaÅ¡to ovaj korak?

**Problem:** Faker generira podatke u memoriji - kad se skripta zavrÅ¡i, podaci nestaju.

**RjeÅ¡enje:** Spremamo podatke u Parquet datoteke koje:
- Ostaju na disku trajno
- BigQuery moÅ¾e direktno uÄitati
- ÄŒuvaju tipove podataka (ne kao CSV gdje je sve string)

## Veza s prethodnim korakom (Faker)

Faker je generirao `List[Customer]`, `List[Order]`, itd. u memoriji.
Parquet exporter pretvara te liste u DataFrame i sprema na disk.

```
RAM: [Customer objects] â†’ DataFrame â†’ Disk: customers.parquet
```

## Å to slijedi? (BigQuery/Snowflake)

Parquet datoteke uÄitavamo u cloud data warehouse (BigQuery ili Snowflake) gdje Ä‡e dbt raditi transformacije.

---

## Å to je Parquet?

**Columnar (stupÄani) format** za spremanje podataka, optimiziran za analitiku.

## ZaÅ¡to Parquet umjesto CSV?

| CSV | Parquet |
|-----|---------|
| ÄŒita sve stupce | ÄŒita samo potrebne stupce |
| Nema kompresiju | 2-10x manja veliÄina |
| Sve je string | ÄŒuva tipove (int, date, decimal) |
| Nema schema | Schema ugraÄ‘ena u file |

## Kada koristiti?

âœ… **Parquet:** Analitika, data warehouse, veliki dataseti
âŒ **CSV:** Jednostavna razmjena podataka, Excel kompatibilnost

## KljuÄni koncepti

### 1. Columnar vs Row storage

```
ROW (CSV):        COLUMN (Parquet):
id,name,age       id: [1,2,3]
1,Ivan,25         name: [Ivan,Ana,Pero]
2,Ana,30          age: [25,30,28]
3,Pero,28
```

Ako trebaÅ¡ samo `age` stupac:
- CSV: uÄitaj cijeli file
- Parquet: uÄitaj samo `age` blok

### 2. Kompresija

Parquet koristi kompresiju (snappy, gzip). Isti podaci = manje prostora.

### 3. Schema

Parquet "zna" da je `price` Decimal, `created_at` DateTime. Nema parsiranja stringova.

## Pandas + Parquet

```python
# Spremanje
df.to_parquet("file.parquet")

# ÄŒitanje
df = pd.read_parquet("file.parquet")

# ÄŒitanje samo nekih stupaca
df = pd.read_parquet("file.parquet", columns=["id", "name"])
```

## Korisni linkovi

- [Apache Parquet](https://parquet.apache.org/)
- [Pandas Parquet docs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html)
