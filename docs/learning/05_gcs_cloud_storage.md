# ğŸ“š GCS (Google Cloud Storage) - Cloud File Storage

## Gdje smo u projektu?

```
[1. Pydantic] â†’ [2. Faker] â†’ [3. Parquet] â†’ [4. BigQuery] â†’ [5. GCS] â†’ [6. dbt]
     âœ…            âœ…            âœ…             âœ…          ğŸ‘ˆ TU SMO
```

## ZaÅ¡to ovaj korak?

**Problem:** Parquet datoteke su samo na tvom raÄunalu:
- Ako ti crkne laptop = podaci izgubljeni
- Kolege ne mogu pristupiti
- Nema verzioniranja

**RjeÅ¡enje:** Upload u GCS (Cloud Storage):
- Backup u cloudu
- Pristup s bilo kojeg raÄunala
- Verzije po datumu
- BigQuery moÅ¾e Äitati direktno iz GCS-a

## Veza s prethodnim korakom (BigQuery)

Prije smo uÄitavali Parquet direktno u BigQuery s lokalnog diska.
Sada imamo staging layer:

```
PRIJE:  Lokalno â†’ BigQuery

SADA:   Lokalno â†’ GCS â†’ BigQuery
                   â†‘
            Backup/Staging
```

## Å to slijedi? (dbt)

S podacima u BigQuery-u, dbt Ä‡e raditi transformacije:
- Staging modeli (ÄiÅ¡Ä‡enje)
- Mart modeli (business logika)

---

## KljuÄni koncepti

### 1. Bucket

**Bucket** = kontejner za datoteke u cloudu (kao folder).

```
gs://ecommerce-raw-dorian/           â† Bucket
â”œâ”€â”€ 2024-01-25/                      â† "Folder" (prefix)
â”‚   â”œâ”€â”€ customers.parquet
â”‚   â””â”€â”€ orders.parquet
â””â”€â”€ 2024-01-26/
    â””â”€â”€ ...
```

### 2. Object (Blob)

Svaka datoteka u bucketu je **object** (ili blob).

```python
# Object path
gs://bucket-name/folder/file.parquet
```

### 3. gsutil vs Python SDK

Dva naÄina za rad s GCS-om:

```bash
# gsutil (command line)
gsutil cp file.parquet gs://bucket-name/

# Python SDK
from google.cloud import storage
blob.upload_from_filename("file.parquet")
```

### 4. Particioniranje po datumu

Standardni pattern - organiziraj podatke po datumu:

```
gs://bucket/raw/2024-01-25/customers.parquet
gs://bucket/raw/2024-01-26/customers.parquet
```

Prednosti:
- Lako pronaÄ‡i podatke za odreÄ‘eni dan
- MoÅ¾eÅ¡ obrisati stare podatke
- BigQuery moÅ¾e Äitati samo odreÄ‘ene particije

---

## Python kod za GCS

```python
from google.cloud import storage

# Kreiraj klijent
client = storage.Client.from_service_account_json("credentials.json")

# Dohvati bucket
bucket = client.bucket("ecommerce-raw-dorian")

# Upload datoteke
blob = bucket.blob("raw/customers.parquet")
blob.upload_from_filename("data/raw/customers.parquet")
```

---

## Korisni linkovi

- [GCS Python dokumentacija](https://cloud.google.com/storage/docs/reference/libraries#client-libraries-install-python)
- [gsutil dokumentacija](https://cloud.google.com/storage/docs/gsutil)
